{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>mood</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casual</td>\n",
       "      <td>I Didn't Mean To</td>\n",
       "      <td>Verse One:\\r\\n\\r\\nAlright I might\\r\\nHave had ...</td>\n",
       "      <td>Hip Hop/Rap</td>\n",
       "      <td>sad</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>Something Girls</td>\n",
       "      <td>Adam Ant/Marco Pirroni\\r\\nEvery girl is a some...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>happy</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gob</td>\n",
       "      <td>Face the Ashes</td>\n",
       "      <td>I've just erased it's been a while, I've got a...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>sad</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lionel Richie</td>\n",
       "      <td>Tonight Will Be Alright</td>\n",
       "      <td>Little darling \\r\\nWhere you've been so long \\...</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>happy</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue Rodeo</td>\n",
       "      <td>Floating</td>\n",
       "      <td>Lead Vocal by Greg\\r\\n\\r\\nWell, these late nig...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>sad</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                    title  \\\n",
       "0         Casual         I Didn't Mean To   \n",
       "1       Adam Ant          Something Girls   \n",
       "2            Gob           Face the Ashes   \n",
       "3  Lionel Richie  Tonight Will Be Alright   \n",
       "4     Blue Rodeo                 Floating   \n",
       "\n",
       "                                              lyrics        genre   mood  year  \n",
       "0  Verse One:\\r\\n\\r\\nAlright I might\\r\\nHave had ...  Hip Hop/Rap    sad  1994  \n",
       "1  Adam Ant/Marco Pirroni\\r\\nEvery girl is a some...         Rock  happy  1982  \n",
       "2  I've just erased it's been a while, I've got a...         Rock    sad  2007  \n",
       "3  Little darling \\r\\nWhere you've been so long \\...          R&B  happy  1986  \n",
       "4  Lead Vocal by Greg\\r\\n\\r\\nWell, these late nig...         Rock    sad  1987  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('song_dataset_lyrics1.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: ['sad' 'happy' 'sad' 'happy' 'sad'] ...\n",
      "after: [1 0 1 0 1] ...\n"
     ]
    }
   ],
   "source": [
    "X_train = df['lyrics'].values\n",
    "y_train = df['mood'].values\n",
    "print('before: %s ...' %y_train[:5])\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "\n",
    "print('after: %s ...' %y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open('./lyrics_label_encoder_py.pkl', 'wb')\n",
    "pickle.dump(le, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Porter Stemmer\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "porter_stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def porter_tokenizer(text, stemmer=porter_stemmer):\n",
    "    \"\"\"\n",
    "    A Porter-Stemmer-Tokenizer hybrid to splits sentences into words (tokens) \n",
    "    and applies the porter stemming algorithm to each of the obtained token. \n",
    "    Tokens that are only consisting of punctuation characters are removed as well.\n",
    "    Only tokens that consist of more than one letter are being kept.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "    text : `str`. \n",
    "      A sentence that is to split into words.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    \n",
    "    no_punct : `str`. \n",
    "      A list of tokens after stemming and removing Sentence punctuation patterns.\n",
    "    \n",
    "    \"\"\"\n",
    "    lower_txt = text.lower()\n",
    "    tokens = nltk.wordpunct_tokenize(lower_txt)\n",
    "    stems = [porter_stemmer.stem(t) for t in tokens]\n",
    "    no_punct = [s for s in stems if re.match('^[a-zA-Z]+$', s) is not None]\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['don', 't', 'want', 'swim']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter_tokenizer(\"Don't !!! --- want swimming. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words ['i', 'me', 'my', 'myself', 'we'] ...\n"
     ]
    }
   ],
   "source": [
    "with open('./stopwords.txt', 'r') as infile:\n",
    "    stop_words = infile.read().splitlines()\n",
    "print('stop words %s ...' %stop_words[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "            encoding='utf-8',\n",
    "            decode_error='replace',\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            binary=False,\n",
    "            stop_words=stop_words,\n",
    "            tokenizer=porter_tokenizer,\n",
    "            ngram_range=(1,1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "Vocabulary: ['didn', 'like', 'swim', 'swimmer']\n",
      "Sentence 1: [[0 1 1 1]]\n",
      "Sentence 2: [[0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"123 1 The\\n swimmer likes swimming so he swims. Don't didn`t\"]\n",
    "\n",
    "vec = vec.fit(vocab)\n",
    "\n",
    "sentence1 = vec.transform([u'The swimmer likes swimming.'])\n",
    "sentence2 = vec.transform(['The\\nswimmer \\nswims.'])\n",
    "\n",
    "\n",
    "print('TEST:')\n",
    "print('Vocabulary: %s' %vec.get_feature_names())\n",
    "print('Sentence 1: %s' %sentence1.toarray())\n",
    "print('Sentence 2: %s' %sentence2.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "            encoding='utf-8',\n",
    "            decode_error='replace',\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            binary=False,\n",
    "            stop_words=stop_words,\n",
    "            tokenizer=porter_tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:\n",
      "Vocabulary: ['didn', 'like', 'swim', 'swimmer']\n",
      "Sentence 1: [[0.         0.57735027 0.57735027 0.57735027]]\n",
      "Sentence 2: [[0.         0.         0.70710678 0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "vocab = [\"123 1 The\\n swimmer likes swimming so he swims. Don't didn`t\"]\n",
    "\n",
    "tfidf = tfidf.fit(vocab)\n",
    "\n",
    "sentence1 = tfidf.transform([u'The swimmer likes swimming.'])\n",
    "sentence2 = tfidf.transform(['The\\nswimmer \\nswims.'])\n",
    "\n",
    "\n",
    "print('TEST:')\n",
    "print('Vocabulary: %s' %tfidf.get_feature_names())\n",
    "print('Sentence 1: %s' %sentence1.toarray())\n",
    "print('Sentence 2: %s' %sentence2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8550\n"
     ]
    }
   ],
   "source": [
    "vec = vec.fit(X_train.ravel())\n",
    "print('Vocabulary size: %s' %len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# `pos_label` for positive class, since we have sad=1, happy=0\n",
    "\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, greater_is_better=True, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samarth\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Samarth\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.620\n",
      "Best parameters set:\n",
      "\tvect__binary: False\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
      "\tvect__tokenizer: <function porter_tokenizer at 0x0000024EA6DAC950>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "pipeline_3 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters_3 = dict(\n",
    "    vect__binary=[False],\n",
    "    vect__stop_words=[stop_words, None],\n",
    "    vect__tokenizer=[porter_tokenizer, None],\n",
    "    vect__ngram_range=[(1,1), (2,2), (3,3)],\n",
    ")\n",
    "\n",
    "grid_search_3 = GridSearchCV(pipeline_3, \n",
    "                           parameters_3, \n",
    "                           n_jobs=1, \n",
    "                           verbose=1,\n",
    "                           scoring=f1_scorer,\n",
    "                           cv=10\n",
    "                )\n",
    "\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline_3.steps])\n",
    "print(\"parameters:\")\n",
    "grid_search_3.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search_3.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters_3 = grid_search_3.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters_3.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters_3[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy import interp\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy import interp\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "clf_2 = Pipeline([\n",
    "                  ('vect', CountVectorizer(\n",
    "                                           binary=False,\n",
    "                                           stop_words=stop_words,\n",
    "                                           tokenizer=porter_tokenizer,\n",
    "                                           ngram_range=(1,1),\n",
    "                                           )\n",
    "                 ),\n",
    "                 ('clf', MultinomialNB()),\n",
    "                 ])\n",
    "\n",
    "colors = ['#1947D1']\n",
    "linestyles = ['-']\n",
    "classifiers = [clf_2]\n",
    "labels = ['1: Multinomial NB, stop words, porter stemmerx`, \\nuni-gram, df']\n",
    "\n",
    "for clf,col,ls,lab in zip(classifiers, colors, linestyles, labels):\n",
    "    \n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    cv = StratifiedKFold(y_train, n_folds=10, random_state=123)\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = clf.fit(X_train[train], y_train[train]).predict_proba(X_train[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, \n",
    "             mean_tpr, \n",
    "             color=col, \n",
    "             linestyle=ls,\n",
    "             label='%s (ROC AUC = %0.2f)' % (lab, mean_auc), \n",
    "             lw=2\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Guessing')    \n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - max_features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colors = ['#1947D1', '#CC3300', 'k', '#339933']\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "params = [1000,3000,5000,None]\n",
    "labels = ['max features = 1000', \n",
    "          'max features = 3000',\n",
    "          'max features = 5000',\n",
    "          'max features = all (=8550)',\n",
    "          ]\n",
    "\n",
    "for param,col,ls,lab in zip(params, colors, linestyles, labels):\n",
    "\n",
    "    clf = Pipeline([\n",
    "                         ('vect', CountVectorizer(\n",
    "                                                  binary=False,\n",
    "                                                  stop_words=stop_words,\n",
    "                                                  tokenizer=porter_tokenizer,\n",
    "                                                  ngram_range=(1,1),\n",
    "                                                  max_features=param,\n",
    "                                                  )\n",
    "                          ),\n",
    "                         ('clf', MultinomialNB()),\n",
    "                        ])\n",
    "    \n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    cv = StratifiedKFold(y_train, n_folds=10, random_state=123)\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = clf.fit(X_train[train], y_train[train]).predict_proba(X_train[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, \n",
    "             mean_tpr, \n",
    "             color=col, \n",
    "             linestyle=ls,\n",
    "             label='%s (ROC AUC = %0.2f)' % (lab, mean_auc), \n",
    "             lw=2\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Guessing')    \n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multinomial NB, stop words, porter stemmer, uni-gram, tf-idf')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamter Tuning - min_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colors = ['#1947D1', '#CC3300', 'k', ]\n",
    "linestyles = ['-', '--', '-.']\n",
    "params = [1, 0.1, 0.01]\n",
    "labels = ['no cutoff',\n",
    "          'min. df = 0.1', \n",
    "          'min. df = 0.01',\n",
    "          ]\n",
    "\n",
    "for param,col,ls,lab in zip(params, colors, linestyles, labels):\n",
    "\n",
    "    clf = Pipeline([\n",
    "                         ('vect', CountVectorizer(\n",
    "                                                  binary=False,\n",
    "                                                  stop_words=stop_words,\n",
    "                                                  tokenizer=porter_tokenizer,\n",
    "                                                  ngram_range=(1,1),\n",
    "                                                  min_df=param,\n",
    "                                                  )\n",
    "                          ),\n",
    "                         ('clf', MultinomialNB()),\n",
    "                        ])\n",
    "    \n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    cv = StratifiedKFold(y_train, n_folds=10, random_state=123)\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = clf.fit(X_train[train], y_train[train]).predict_proba(X_train[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, \n",
    "             mean_tpr, \n",
    "             color=col, \n",
    "             linestyle=ls,\n",
    "             label='%s (ROC AUC = %0.2f)' % (lab, mean_auc), \n",
    "             lw=2\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Guessing')    \n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Multinomial NB, stop words, porter stemmer, uni-gram, tf-idf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - alpha"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colors = ['#1947D1', '#CC3300', 'k', '#339933']\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "params = [0.05, 0.1, 1.0, 2.0]\n",
    "labels = ['alpha = 0.05', \n",
    "          'alpha = 0.1',\n",
    "          'alpha = 1.0',\n",
    "          'alpha = 2.0',\n",
    "          ]\n",
    "\n",
    "for param,col,ls,lab in zip(params, colors, linestyles, labels):\n",
    "\n",
    "    clf = Pipeline([\n",
    "                         ('vect', CountVectorizer(\n",
    "                                                  binary=False,\n",
    "                                                  stop_words=stop_words,\n",
    "                                                  tokenizer=porter_tokenizer,\n",
    "                                                  ngram_range=(1,1),\n",
    "                                                  \n",
    "                                                  )\n",
    "                          ),\n",
    "                         ('clf', MultinomialNB(alpha=param)),\n",
    "                        ])\n",
    "    \n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    cv = StratifiedKFold(y_train, n_folds=10, random_state=123)\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = clf.fit(X_train[train], y_train[train]).predict_proba(X_train[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, \n",
    "             mean_tpr, \n",
    "             color=col, \n",
    "             linestyle=ls,\n",
    "             label='%s (ROC AUC = %0.2f)' % (lab, mean_auc), \n",
    "             lw=2\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Guessing')    \n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Multinomial NB, stop words, porter stemmer, uni-gram, tf-idf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-gram Comparison"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "colors = ['#1947D1', '#CC3300', 'k', ]\n",
    "linestyles = ['-', '--', '-.',]\n",
    "params = [(1,1), (2,2), (3,3),]\n",
    "labels = ['1-gram', \n",
    "          '2-gram',\n",
    "          '3-gram',\n",
    "          ]\n",
    "\n",
    "for param,col,ls,lab in zip(params, colors, linestyles, labels):\n",
    "\n",
    "    clf = Pipeline([\n",
    "                         ('vect', CountVectorizer(\n",
    "                                                  binary=False,\n",
    "                                                  stop_words=stop_words,\n",
    "                                                  tokenizer=porter_tokenizer,\n",
    "                                                  ngram_range=param,\n",
    "                                                  \n",
    "                                                  )\n",
    "                          ),\n",
    "                         ('clf', MultinomialNB(alpha=1.0)),\n",
    "                        ])\n",
    "    \n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    cv = StratifiedKFold(y_train, n_folds=10, random_state=123)\n",
    "\n",
    "    for i, (train, test) in enumerate(cv):\n",
    "        probas_ = clf.fit(X_train[train], y_train[train]).predict_proba(X_train[test])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_train[test], probas_[:, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    mean_tpr /= len(cv)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, \n",
    "             mean_tpr, \n",
    "             color=col, \n",
    "             linestyle=ls,\n",
    "             label='%s (ROC AUC = %0.2f)' % (lab, mean_auc), \n",
    "             lw=2\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random Guessing')    \n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title('Multinomial NB, stop words, porter stemmer, uni-gram, tf-idf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['i', 'me',...50>,\n",
       "        vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clf = Pipeline([\n",
    "                ('vect', CountVectorizer(\n",
    "                                         binary=False,\n",
    "                                         stop_words=stop_words,\n",
    "                                         tokenizer=porter_tokenizer,\n",
    "                                         ngram_range=(1,1),\n",
    "                                         )\n",
    "                ),\n",
    "                ('clf', MultinomialNB(alpha=1.0)),\n",
    "               ])\n",
    "final_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAACECAYAAADVwmSJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZIJIkgb/D9Mq1IQsY2afAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24ea7f622b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "cm = metrics.confusion_matrix(y_train, final_clf.predict(X_train))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "mpl.rc(\"figure\", figsize=(4, 2))\n",
    "\n",
    "hm = sns.heatmap(cm, \n",
    "            cbar=False,\n",
    "            annot=True, \n",
    "            square=True,\n",
    "            fmt='d',\n",
    "            yticklabels=['happy','sad'],\n",
    "            xticklabels=['happy','sad'],\n",
    "            cmap='Blues'\n",
    "            )\n",
    "plt.title('Confusion matrix - Training dataset')\n",
    "plt.ylabel('actual class')\n",
    "plt.xlabel('predicted class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_excel('valid_songs_200.xlsx')\n",
    "\n",
    "X_valid = df['lyrics'].values \n",
    "y_valid = df['mood'].values\n",
    "\n",
    "y_valid = le.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANIAAACECAYAAADlTnWoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWCIxjAT8P5FbBUdhDuBOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24ea7ec1828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_valid, final_clf.predict(X_valid))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "mpl.rc(\"figure\", figsize=(4, 2))\n",
    "\n",
    "hm = sns.heatmap(cm, \n",
    "            cbar=False,\n",
    "            annot=True, \n",
    "            square=True,\n",
    "            fmt='d',\n",
    "            yticklabels=['happy','sad'],\n",
    "            xticklabels=['happy','sad'],\n",
    "            cmap='Blues'\n",
    "            )\n",
    "plt.title('Confusion matrix - Validation dataset')\n",
    "plt.ylabel('actual class')\n",
    "plt.xlabel('predicted class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom scorer methods to account for positive-negative class labels\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# `pos_label` for positive class, since we have sad=1, happy=0\n",
    "\n",
    "acc_scorer = metrics.make_scorer(metrics.accuracy_score, greater_is_better=True)\n",
    "pre_scorer = metrics.make_scorer(metrics.precision_score, greater_is_better=True, pos_label=0)\n",
    "rec_scorer = metrics.make_scorer(metrics.recall_score, greater_is_better=True, pos_label=0)\n",
    "f1_scorer = metrics.make_scorer(metrics.f1_score, greater_is_better=True, pos_label=0)\n",
    "auc_scorer = metrics.make_scorer(metrics.roc_auc_score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'Data':['Training', 'Validation'],\n",
    "     'ACC (%)':[],\n",
    "     'PRE (%)':[],\n",
    "     'REC (%)':[],\n",
    "     'F1 (%)':[],\n",
    "     'ROC AUC (%)':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['ACC (%)'].append(acc_scorer(estimator=final_clf, X=X_train, y_true=y_train))\n",
    "d['PRE (%)'].append(pre_scorer(estimator=final_clf, X=X_train, y_true=y_train))\n",
    "d['REC (%)'].append(rec_scorer(estimator=final_clf, X=X_train, y_true=y_train))\n",
    "d['F1 (%)'].append(f1_scorer(estimator=final_clf, X=X_train, y_true=y_train))\n",
    "d['ROC AUC (%)'].append(auc_scorer(estimator=final_clf, X=X_train, y_true=y_train))\n",
    "\n",
    "d['ACC (%)'].append(acc_scorer(estimator=final_clf, X=X_valid, y_true=y_valid))\n",
    "d['PRE (%)'].append(pre_scorer(estimator=final_clf, X=X_valid, y_true=y_valid))\n",
    "d['REC (%)'].append(rec_scorer(estimator=final_clf, X=X_valid, y_true=y_valid))\n",
    "d['F1 (%)'].append(f1_scorer(estimator=final_clf, X=X_valid, y_true=y_valid))\n",
    "d['ROC AUC (%)'].append(auc_scorer(estimator=final_clf, X=X_valid, y_true=y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC (%)</th>\n",
       "      <th>PRE (%)</th>\n",
       "      <th>REC (%)</th>\n",
       "      <th>F1 (%)</th>\n",
       "      <th>ROC AUC (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>94.0</td>\n",
       "      <td>93.47</td>\n",
       "      <td>93.05</td>\n",
       "      <td>93.26</td>\n",
       "      <td>93.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>68.0</td>\n",
       "      <td>75.95</td>\n",
       "      <td>57.14</td>\n",
       "      <td>65.22</td>\n",
       "      <td>68.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ACC (%)  PRE (%)  REC (%)  F1 (%)  ROC AUC (%)\n",
       "Training       94.0    93.47    93.05   93.26        93.91\n",
       "Validation     68.0    75.95    57.14   65.22        68.57"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perform = pd.DataFrame(d)\n",
    "df_perform = df_perform[['ACC (%)', 'PRE (%)', 'REC (%)', 'F1 (%)', 'ROC AUC (%)']]\n",
    "df_perform.index=(['Training', 'Validation'])\n",
    "df_perform = df_perform*100\n",
    "df_perform = np.round(df_perform, decimals=2)\n",
    "df_perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyrics_clf_1000 = final_clf\n",
    "\n",
    "pickle_out = open('./lyrics_clf_1000_py27.pkl', 'wb')\n",
    "pickle.dump(lyrics_clf_1000, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
